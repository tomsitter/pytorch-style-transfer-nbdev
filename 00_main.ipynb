{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp main\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "> CLI for the PyTorch neural style transfer application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from time import time\n",
    "\n",
    "import click\n",
    "import torchvision.models as models\n",
    "\n",
    "from pytorch_nst.config import device\n",
    "from pytorch_nst.util import image_loader, imshow, random_img, save_image, show_all_images\n",
    "from pytorch_nst.nst import run_style_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def validate_layers(ctx, param, value):\n",
    "    try:\n",
    "        layers = [l for l in value.split(',')]\n",
    "        convs = [(int(p),int(l)) for p,l in [layer.split(\"_\") for layer in layers]]\n",
    "        assert all(isinstance(l, int) and isinstance(p, int) for p,l in convs)\n",
    "        return [f'conv{l}' for l in layers]\n",
    "    except ValueError:\n",
    "        raise click.BadParameter('Layers need to be ints seperated by commas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@click.command()\n",
    "@click.option('-c', '--content', \n",
    "                default='./examples/content.jpg', \n",
    "                prompt='Content image',\n",
    "                help='path to content image',\n",
    "                show_default=True)\n",
    "@click.option('-s', '--style', \n",
    "                default='./examples/style.jpg', \n",
    "                prompt='Style image',\n",
    "                help='path to style image',\n",
    "                show_default=True)\n",
    "@click.option('-o', '--output', \n",
    "                default='./output/generated-' +  str(int(time())) + '.jpg', \n",
    "                prompt=False,\n",
    "                help='path to save generated image',\n",
    "                show_default=True)\n",
    "@click.option('--style_weight', default=1000000, prompt=False, show_default=True)\n",
    "@click.option('--style_layers', callback=validate_layers, \n",
    "                default='1_1,2_1,3_1,4_1,5_1', show_default=True,\n",
    "                help='Conv Layers to use for style loss')\n",
    "@click.option('--steps', default=300, prompt=False, show_default=True)\n",
    "@click.option('--random_input', is_flag=True,\n",
    "                help='Will start with random noise if set, otherwise content image')\n",
    "def cli(content, style, output, style_weight, style_layers, steps, random_input):\n",
    "    \"\"\"Command Line interface for running neural style transfer with PyTorch\"\"\"\n",
    "    style_img = image_loader(style)\n",
    "    content_img = image_loader(content)\n",
    "    assert style_img.size() == content_img.size(), \\\n",
    "        \"Style and Content images must be the same size\"\\\n",
    "\n",
    "    if random_input:\n",
    "        input_img = random_img()\n",
    "    else:\n",
    "        input_img = content_img.clone()\n",
    "\n",
    "    # Load a pre-trained VGG network\n",
    "    print(\"Loading pre-trained VGG19. This may take a while the first run...\")\n",
    "    \n",
    "    vgg = models.vgg19(pretrained=True).features #Conv2D and pooling layers\n",
    "    \n",
    "    #for param in vgg.parameters():\n",
    "    #    param.requires_grad_(False)\n",
    "        \n",
    "    vgg.to(device).eval()\n",
    "    #cnn = models.resnet50(pretrained=True).to(device).eval()\n",
    "\n",
    "    gen_img = run_style_transfer(vgg, \n",
    "                                 content_img, \n",
    "                                 style_img, \n",
    "                                 input_img, \n",
    "                                 style_layers=style_layers, \n",
    "                                 style_weight=style_weight, \n",
    "                                 num_steps=steps)\n",
    "\n",
    "    show_all_images(content_img, style_img, gen_img, title=\"Generated Image\")\n",
    "\n",
    "    if click.confirm('Do you want to save the generated image?'):\n",
    "        save_image(gen_img, output)\n",
    "        print(f'Saved to {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "show_doc(cli)\n",
    "show_doc(validate_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-style-transfer-nbdev",
   "language": "python",
   "name": "pytorch-style-transfer-nbdev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
